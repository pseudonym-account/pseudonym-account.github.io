<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="RL, MOP, LAP, SAC">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Dynamic Reference RL</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  
</nav>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Enhancing Sample Efficiency and Exploration via Dynamic Reference-Based Reinforcement Learning</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <!-- <a href="">Anonymous Author</a></span>  -->
              Anonymous Author
          </div>

          <!-- <div class="is-size-5 publication-authors">
            <span class="author-block">UPF</span>
          </div> -->

          <!-- <div class="column has-text-centered"> 
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              
              <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>
          </div> -->

        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In reinforcement learning, balancing exploration and exploitation is crucial to achieving optimal results. 
            Traditional methods use regularizers to prevent the policy from becoming deterministic too early like penalizing deviations from a predefined reference policy. 
          </p>
          <p>
            This paper explores a novel approach where a reference policy, termed "anchor policy," is trained alongside the main policy to guide exploration. 
            We employ Kullback–Leibler divergence as a regularization technique, allowing the anchor policy to evolve in response to the learning environment. 
            We prove the convergence of the anchor policy iteration method and validate our theory using an anchor actor-critic framework. 
            Our experiments on challenging environments show that incorporating an anchor policy improves exploration and leads to better performance in benchmarks compared to state of the art baselines. 
            This research suggests that dynamically training an anchor policy alongside the main policy can enhance the learning outcomes. 
            It opens the door for further exploration of adaptive reference policies in complex reinforcement learning environments.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section id="videos" class="section">
  <div class="container ">

    <div class="columns is-centered">

      <div class="column">
        <div class="content">
          <h2 class="title is-3">Soft Actor Critic</h2>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/video_sac.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>

      <div class="column">
        <h2 class="title is-3">Dynamic Reference MOP</h2>
        <div class="columns is-centered">
          <div class="column content">
            <!-- <p>
              As a byproduct of our method, we can also solve the matting problem by ignoring
              samples that fall outside of a bounding box during rendering.
            </p> -->
            <video id="matting-video" controls playsinline height="100%">
              <source src="./static/videos/video_mop.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>

      <div class="column">
        <h2 class="title is-3">Dynamic Reference Lap</h2>
        <div class="columns is-centered">
          <div class="column content">
            <video id="matting-video" controls playsinline height="100%">
              <source src="./static/videos/video_lap.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div>

    <!--/ Matting. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <div class="content has-text-justified">
          <h2 class="title is-3 has-text-centered">Visual Effects</h2>
          <img src="static/images/comparison_ant_diagram.jpg">
        </div>
        <div class="content has-text-justified">
          <p>
            1. <strong>Uniform Anchor</strong>: Demonstrates indiscriminate exploration with no strategic guidance, leading to inefficient learning paths.
          </p>

          <p>
            2. <strong>Fixed Pretrained Anchor</strong>: Shows initial efficient guidance that becomes ineffective after environmental changes, as the fixed path does not adapt to new conditions.
          </p>

          <p>
            3. <strong>Adaptive Anchor</strong> Illustrates dynamic adjustment to guidance paths in response to environmental changes, maintaining relevant and efficient exploration throughout the learning process.
          </p>
          <p>
            An <i>Anchor Policy</i> is a stable or separately learned policy with predefined objectives that serves as a 'reference' during the training of a target policy -- the target policy is designed to solve the Markov Decision Process (MDP) by maximizing the expected reward alone.
            By leveraging an anchor policy, the training process can be guided by smartly-engineered understanding of the environment.  
            This not only bridges the exploration-exploitation dilemma but also ensures that the learning trajectory of the target policy remains bounded by certain desirable characteristics of the anchor.  
          </p>

        </div>
      </div>
    </div>
    
    <div class="columns is-centered">
      <div class="column">
        <div class="content has-text-justified">
          <h2 class="title is-3 has-text-centered">Visual Effects</h2>
          <div class="content has-text-centered"">
            <img src="static/images/ants3_crop.jpg" style="width: 75%;">
          </div>
          <p>
            <strong>Anchor Lap</strong> uses a Laplacian operator derived from the policy's state transition distribution, enabling a graph-based representation of the environment. 
            This method applies stochastic optimization to derive the smallest eigen-functions of the Laplacian, effectively representing the environment. 
            To ensure proper alignment of the eigen-functions, the method incorporates a soft constraint for ortho-normality during stochastic optimization. 
            The optimization process samples transitions and pairs of states, employing stochastic gradient descent to learn the eigen-functions.
          </p> 
          <h4 class="text-center desktop-only">
              $$
              \begin{equation}
                  R(s_{t}, a_{t}) = \frac{||\phi(s_{t+1})-\phi(s_{t+1})||_{2}^2}{||\phi(s_{t+1})||_{2}^2 + ||\phi(s_{t})||_{2}^2}
              \end{equation}
              $$
          </h4> 
        </div>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column">
        <div class="content has-text-justified">
          <h2 class="title is-3 has-text-centered">Visual Effects</h2>
          
        </div>
      </div>
    </div>

  </div>
</section>


<!-- 
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content has-text-centered">
          <p>
            The website template was borrowed from <a href="http://mgharbi.com/">Michaël Gharbi</a> and <a href="https://jonbarron.info/">Jon Barron</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
